{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f018216-1628-404f-8a72-5c9999c7709d",
   "metadata": {},
   "source": [
    "## Dependency prep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3abf4-4451-44b1-bb36-5e9936d2ac5a",
   "metadata": {},
   "source": [
    "Install a pip dependency for later downloading of model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a8ce9-ce47-46cf-8d3c-815be8952c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0ae5b-069a-4b1c-b555-ba64e03435cf",
   "metadata": {},
   "source": [
    "Prepare train data, here we use an aligned corpus in stanford_alpaca repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b694e-7c36-4ade-af31-12de1ca10d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0a813-ed39-4ea3-b957-1a92472690a2",
   "metadata": {},
   "source": [
    "Download s5cmd for faster S3 transfer than 'aws s3 cp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9831c-5a85-4eea-81a1-c4fc5a756f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz | tar -xz s5cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387aaecd-8d00-404d-8e3c-75f002b7bf48",
   "metadata": {},
   "source": [
    "Use SageMaker default bucket, or ANY S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198d661-8b7b-4190-b7c2-1254eba34302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_default_bucket = sess.default_bucket()\n",
    "print(sagemaker_default_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896d87d-1afa-4700-a39c-47ec4cc8b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b32c1305-70e9-4318-a63a-5222a8576eeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dowloading Model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610962b6-8cda-4396-b117-73be8cc95803",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_cache_path = Path(\"./llama2-model\")\n",
    "local_cache_path.mkdir(exist_ok=True)\n",
    "\n",
    "model_name = \"TheBloke/Llama-2-7B-fp16\" # choose a 3rd party hf model\n",
    "\n",
    "# Only download pytorch checkpoint files\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.model\"]\n",
    "\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    cache_dir=local_cache_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a67158-583c-49bd-a979-98f96d923ef4",
   "metadata": {},
   "source": [
    "Find where the model artifacts (e.g. config.json, *.bin) sits and copy the path to following variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e65d1e-f415-4eed-bbd4-0e92bda3efdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snapshot_model_path = 'llama2-model/models--TheBloke--Llama-2-7B-fp16/snapshots/ec92360670debf11267ccece99b8e65a8c723802' # change to the correct path model exists\n",
    "s3_destination_path = f's3://{sagemaker_default_bucket}/bloke-llama2-7b-fp16/' # change to your own s3 path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2f29c-9c7c-40e6-8f4e-5fd0b541d7e5",
   "metadata": {},
   "source": [
    "Copy the model files from notebook instance to S3, as training instances will access model artifacts from S3 (NOT from this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e4a4e-7bda-4eb9-bf88-0b3347c7fb83",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {snapshot_model_path} {s3_destination_path} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8e50a-9e6d-4632-b1f7-65982055238d",
   "metadata": {},
   "source": [
    "Have to release the Notebook Instance Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d28f2-f9d1-474a-a810-cbacc8a641af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf llama2-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02bc39-59ba-4d4d-9fd9-776955fd1cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b44b427b-e897-46ec-8a54-0e337759c869",
   "metadata": {},
   "source": [
    "## Dowloading Model from S3 presign link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef48106-d17c-4174-a0c6-d3697f292efa",
   "metadata": {},
   "source": [
    "HuggingFace might have some throttling mechanism, if download requests happen in a short time. To avoid this, we use a S3 presign link, which will be distributed during the Workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0201f-0ed1-4890-80b9-b7b4aa2f85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O llama2-model.zip \"PASTE-THE-S3-PRESIGN-LINK-HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae122f80-6e6c-480b-be7c-238d4630d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip llama2-model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54deef02-bd34-43c0-8b0d-90e1ae7f1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_model_path = 'llama2-model/' # change to the correct path model exists\n",
    "s3_destination_path = f's3://{sagemaker_default_bucket}/bloke-llama2-7b-fp16/' # change to your own s3 path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e11f24-a160-4a27-8df7-169fd803fbd1",
   "metadata": {},
   "source": [
    "We use s5cmd instead of 'aws s3 cp' for faster transfering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161efe6-ce4d-4283-8be3-74d2f8b7176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./s5cmd\n",
    "!./s5cmd sync {zip_model_path} {s3_destination_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a643f10-c5e5-4043-9a92-39f4929e81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf llama2-model.zip\n",
    "!rm -rf llama2-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59ddfa-924f-4853-941b-b8cc72ba7a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
